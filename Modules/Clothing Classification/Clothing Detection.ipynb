{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud import storage\n",
    "# Line throws error as it was replaced in v2\n",
    "# from google.cloud.vision import types \n",
    "from google.cloud.vision_v1 import types\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import webcolors\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"dsci551-2480c-4e478b8d0198.json\"\n",
    "project_id = \"dsci551-2480c\"\n",
    "region = \"us-east1\"\n",
    "path_to_credentials = \"dsci551-2480c-4e478b8d0198.json\"\n",
    "bucket_name = \"dsci551_storage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture Captured\n",
      "Top\n",
      "normalized_vertices {\n",
      "  x: 0.16308198869228363\n",
      "  y: 0.18126101791858673\n",
      "}\n",
      "normalized_vertices {\n",
      "  x: 0.4218633770942688\n",
      "  y: 0.18126101791858673\n",
      "}\n",
      "normalized_vertices {\n",
      "  x: 0.4218633770942688\n",
      "  y: 0.6214043498039246\n",
      "}\n",
      "normalized_vertices {\n",
      "  x: 0.16308198869228363\n",
      "  y: 0.6214043498039246\n",
      "}\n",
      "\n",
      "Top\n",
      "normalized_vertices {\n",
      "  x: 0.6470707654953003\n",
      "  y: 0.541446328163147\n",
      "}\n",
      "normalized_vertices {\n",
      "  x: 0.9973958134651184\n",
      "  y: 0.541446328163147\n",
      "}\n",
      "normalized_vertices {\n",
      "  x: 0.9973958134651184\n",
      "  y: 0.9972038269042969\n",
      "}\n",
      "normalized_vertices {\n",
      "  x: 0.6470707654953003\n",
      "  y: 0.9972038269042969\n",
      "}\n",
      "\n",
      "['Person', 'Jeans', 'Person', 'Top', 'Top', 'Luggage & bags', 'Glasses', 'Human', 'Fashion', 'Street fashion', 'Standing', 'Eyewear', 'Gesture', 'T-shirt', 'Waist', 'Travel', 'Fun']\n",
      "['Jeans', 'T-shirt'] \n",
      "\n",
      "\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Dictionary for correcting and restricting the classes\n",
    "correction_hashmap = {\"One-piece garment\" : \"Dress\",\n",
    "                      \"Day dress\" : \"Dress\",\n",
    "                      \"High heels\" : \"Heels\",\n",
    "                      \"Sandal\" : \"Heels\",\n",
    "                      \"Basic pump\" : \"Heels\",\n",
    "                      \"Dress shirt\" : \"Shirt\",\n",
    "                      \"Footwear\" : \"Shoe\",\n",
    "                      \"Outdoor shoe\" : \"Shoe\", \n",
    "                      \"Walking shoe\" : \"Shoe\", \n",
    "                      \"Sneakers\" : \"Shoe\",\n",
    "                      \"Miniskirt\" : \"Skirt\",\n",
    "                      \"Active tank\" : \"Tank top\",\n",
    "                      \"Undershirt\" : \"Tank top\"\n",
    "    \n",
    "}\n",
    "# List of labels label detection api call\n",
    "required_labels = [\"One-piece garment\", \"Day dress\", \"Dress\", \n",
    "                  \"High heels\", \"Sandal\", \"Basic pump\", \n",
    "                  \"Jeans\",\n",
    "                  \"Shirt\", \"Dress shirt\",\n",
    "                  \"Shoe\", \"Footwear\", \"Outdoor shoe\", \"Walking shoe\", \"Sneakers\",\n",
    "                  \"Shorts\",\n",
    "                  \"Miniskirt\", \"Skirt\",\n",
    "                  \"Active tank\", \"Undershirt\",\n",
    "                  \"T-shirt\",\n",
    "                  \"Coat\"]\n",
    "\n",
    "# List of labels from object localization api call\n",
    "labels_for_cropping = [\"Top\",\n",
    "                      \"Dress\", \"Day dress\",\n",
    "                      \"High heels\",\n",
    "                      \"Shorts\",\n",
    "                      \"Miniskirt\",\n",
    "                      \"Coat\",\n",
    "                      \"Shoe\"]\n",
    "img_name = \"pic_for_clothing_detection.png\"\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "width  = cam.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "height = cam.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "cam.set(cv2.CAP_PROP_AUTO_EXPOSURE, 3)\n",
    "# Setting exposure to fixed value\n",
    "#cam.set(cv2.CAP_PROP_EXPOSURE, 1) \n",
    "cv2.namedWindow(\"Capture Image of Clothing Item\")\n",
    "pred_clothing_type = [\"\"]\n",
    "x1,x2,x3,x4,y1,y2,y3,y4 = 5,5,5,5,5,5,5,5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    cv2.putText(frame, \"Type = \" + \", \".join(pred_clothing_type), \n",
    "                (220, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, (0, 255, 255))\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"Capture Image of Clothing Item\", frame)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"Picture Captured\")\n",
    "        # Read saved image for vision api call\n",
    "        with io.open(img_name, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "        image = types.Image(content=content)\n",
    "        # Generate labels and (labels + crop hints)\n",
    "        all_labels = client.label_detection(image=image)\n",
    "        labels_and_crops = client.object_localization(image=image).localized_object_annotations\n",
    "        temp_labels_from_crop_list = [labels_and_crops[i].name for i in range(len(labels_and_crops))] \n",
    "        temp_label_list = [all_labels.label_annotations[i].description for i in range(len(all_labels.label_annotations))]\n",
    "        # Combine only the labels from both the sets\n",
    "        combined_labels = temp_labels_from_crop_list + temp_label_list\n",
    "        # Correcting labels manually\n",
    "        for dup in list(correction_hashmap.keys()):\n",
    "            if(dup in combined_labels):\n",
    "                combined_labels[combined_labels.index(dup)] = correction_hashmap[dup]\n",
    "        pred_clothing_type = list(np.intersect1d(combined_labels, required_labels))\n",
    "        if(len(pred_clothing_type) == 0):\n",
    "            pred_clothing_type = [\"Nothing Detected\"]\n",
    "        else:\n",
    "            for detection in labels_and_crops:\n",
    "                if(detection.name in labels_for_cropping):\n",
    "                    print(detection.name)\n",
    "                    print(detection.bounding_poly)\n",
    "                    x1 = int(detection.bounding_poly.normalized_vertices[0].x * width)\n",
    "                    y1 = int(detection.bounding_poly.normalized_vertices[0].y * height)\n",
    "                    x2 = int(detection.bounding_poly.normalized_vertices[1].x * width)\n",
    "                    y2 = int(detection.bounding_poly.normalized_vertices[1].y * height)\n",
    "                    x3 = int(detection.bounding_poly.normalized_vertices[2].x * width)\n",
    "                    y3 = int(detection.bounding_poly.normalized_vertices[2].y * height)\n",
    "                    x4 = int(detection.bounding_poly.normalized_vertices[3].x * width)\n",
    "                    y4 = int(detection.bounding_poly.normalized_vertices[3].y * height)\n",
    "        cv2.imshow(\"Cropped Image\", frame[y1 : y3, x1 : x3])\n",
    "            \n",
    "            \n",
    "        print(combined_labels)\n",
    "        print(pred_clothing_type, \"\\n\\n\")\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480.0 640.0\n"
     ]
    }
   ],
   "source": [
    "print(height, width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
